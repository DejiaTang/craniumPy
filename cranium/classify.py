import os
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import scale
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier

class treeClassifier:

	def __init__(self,df):
		'''A class to manage classifying a landmark dataset using a random forest classifier

		:param pd.DataFrame df: Landmark dataframe containing both sample types with different keys in the stype column

		.. attribute:: treeClassifier.df

			Landmark dataframe containing both sample types with different keys in the stype column
		'''

		self.df = df
		self.Y = self.df['stype']
		print('Sample types:',np.unique(self.Y))
		try:
			self.Xraw = self.df.drop(['stype','Unnamed: 0'],axis=1)
		except:
			self.Xraw = self.df.drop(['stype'],axis=1)

		self.Xnan = self.Xraw.dropna(axis=1,how='all').fillna(self.Xraw.mean())
		self.Xsc = scale(self.Xnan)

	def apply_pca(self,plot=False):
		'''Find optimal number of components and transform data

		:param bool plot: If true, a plot showing the pca parameter sweep will be generated

		.. attribute:: treeClassifier.Xtr

			:attr:`treeClassifier.Xsc` after transformation by PCA

		.. attribute:: treeClassifier.n

			The number of components that captures all of the variability in the data

		.. attribute:: treeClassifier.comp

			pd.DataFrame containing :attr:`treeClassifier.n` rows with the weight of each landmark in the column
		'''

		#Parameter sweep for optimum component number
		evar = []
		for i in range(1,100):
			tpca = PCA(n_components=i)
			tpca.fit(self.Xsc)
			evar.append(tpca.explained_variance_ratio_.sum())

		#Find first n that is close to equaling 1
		self.n = np.nonzero(np.array(evar)>=0.9999)[0][0] +1 #Accounts for list starting at 1
		print(str(self.n),'components accounts for 100 percent of the variability in the data')

		pca = PCA(n_components=self.n)
		pca.fit(self.Xsc)
		self.Xtr = pca.transform(self.Xsc)
		self.comp = pd.DataFrame(pca.components_,columns=self.Xnan.columns)

		if plot == True:
			fig,ax = plt.subplots()
			ax.plot(range(1,200),np.array(evar)*100)
			ax.set_ylabel('Explained Variance (%)')
			ax.set_xlabel('Number of Components')
			ax.axvline(self.n,c='r',label='N_components = '+str(n))
			ax.legend()

	def fit_classifier(self,max_features='sqrt',oob_score=True,n_estimators=500):
		'''Fit a random forest classifer to the transformed data to the trained data

		:param str max_features: Default=``'sqrt'``. See `sklearn.ensemble.RandomForestClassifier`_ for more info.
		:param bool oob_score: Default=``True``. See `sklearn.ensemble.RandomForestClassifier`_ for more info.
		:param int n_estimators: Default=``500``. See `sklearn.ensemble.RandomForestClassifier`_ for more info.

		.. attribute:: treeClassifier.rftree

			Random Forest Classifier generated by `sklearn.ensemble.RandomForestClassifier`_

		.. attributes:: treeClassifier.Importance

			pd.DataFrame containing the relative importance value for each component

		.. _sklearn.ensemble.RandomForestClassifier: <http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
		'''
		self.rftree = RandomForestClassifier(max_features=max_features,
											oob_score=oob_score,
											n_estimators=n_estimators)
		self.rftree.fit(self.Xtr,self.Y)

		self.Importance = pd.DataFrame({'Importance':self.rftree.feature_importances_*100})
		self.Importance = self.Importance.sort_values(by='Importance',axis=0,ascending=False)

		print('Out of Bag score:',str(self.rftree.oob_score_))

	def print_top_components(self,index=None,thresh=None):
		'''Prints a list of top components, which can be limited by index or threshold

		:param int index: Limits how many components will be shown
		:param str thresh: Show only components above the minimum threshold set by thresh
		'''

		if type(index)==int:
			print(self.Importance[self.Importance.index < index])
		elif (type(thresh)==int) | (type(thresh)==str):
			print(self.Importance[self.Importance.Importance > thresh])
		else:
			print(self.Importance)

	def comp_to_arr(self):
		'''Converts dataframe of component landmarks to cartesian array

		.. attribute:: treeClassifier.xarr

			An array listing the bin division points along alpha

		.. attribute:: treeClassifier.tarr

			Array listing the bin division points along theta

		.. attribute:: treeClassifier.cParr

			A cartesian array of the dimensions [len(:attr:`treeClassifier.xarr`),len(:attr:`treeClassifier.tarr`),:attr:`treeClassifier.n`]
			containing the number of points per landmark

		.. attribute:: treeClassifier.cRarr

			A cartesian array of the dimensions [len(:attr:`treeClassifier.xarr`),len(:attr:`treeClassifier.tarr`),:attr:`treeClassifier.n`]
			containing the r distance of the percentile per landmark
		'''

		dfc = reformat_to_cart(self.comp)
		self.xarr = np.round(np.unique(dfc.x),2)
		self.tarr = np.round(np.unique(dfc.t),2)

		self.cParr = np.zeros((len(self.xarr),len(self.tarr),self.n))
		self.cRarr =  np.zeros((len(self.xarr),len(self.tarr),self.n))

		for c in self.comp.columns:
			if len(c.split('_')) == 6:
				amn,amx,tmn,tmx,p,dtype = c.split('_')
				x = np.mean([float(amn),float(amx)])
				t = np.mean([float(tmn),float(tmx)])

				if dtype=='r':
					self.cRarr[np.where(self.xarr==np.round(x,2))[0],np.where(self.tarr==np.round(t,2))[0]] = self.comp[c]
				elif dtype =='pts':
					self.cParr[np.where(self.xarr==np.round(x,2))[0],np.where(self.tarr==np.round(t,2))[0]] = self.comp[c]

	def plot_top_components(self,index=None,thresh=None,path=None):
		'''Plots the r heatmap and pts heatmap according to importance
		:param int index: Limits how many components will be shown
		:param str thresh: Show only components above the minimum threshold set by thresh
		:param str path: Optionally include a path to a directory to save images if desired
		'''
		if type(index)==int:
			L = self.Importance[self.Importance.index < index]
		elif (type(thresh)==int) | (type(thresh)==str):
			L = self.Importance[self.Importance.Importance > thresh]
		else:
			L = self.Importance

		if not hasattr(self,'cParr'):
			self.comp_to_arr()

		for i in L.index:
			fig,axr = plt.subplots(2,2,figsize=(15,4),gridspec_kw={'height_ratios':[1,0.05]})
			plt.suptitle('Importance = '+str(L.Importance.iloc[i]),fontsize=16)

			cb1 = axr[0,0].imshow(np.abs(self.cRarr[:,:,i].T),extent=[self.xarr[0],self.xarr[-1],self.tarr[0],self.tarr[-1]],aspect=10,cmap='viridis')
			cb2 = axr[0,1].imshow(np.abs(self.cParr[:,:,i].T),extent=[self.xarr[0],self.xarr[-1],self.tarr[0],self.tarr[-1]],aspect=10,cmap='viridis')

			axr[0,0].set_title(str(i)+'r')
			plt.colorbar(cb1,cax=axr[1,0],orientation='horizontal')
			axr[0,1].set_title(str(i)+'pts')
			plt.colorbar(cb2,cax=axr[1,1],orientation='horizontal')

			if path != None:
				if os.path.isdir(path):
					fig.savefig(os.path.join(path,'Imp_'+str(L.Importance.iloc[i])+'.jpg'))
